<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="icons/favicon-16x16.png">
    <link rel="icon" type="image/x-icon" href="icons/favicon.ico">
    <title>LLM Chess Leaderboard</title>
    <link rel="stylesheet" href="styles.css">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-4SS6VHS4QF"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-4SS6VHS4QF');
    </script>
    <script src="data.js"></script>
    <script src="script.js"></script>
    <script src="md.js"></script>
</head>
<body>
    <p style="display: none;">
        LLM Chess Leaderboard
        <br>
        Simulating chess games between a Random Player and an LLM. Evaluating Chat Models' (1) chess proficiency and (2) instruction following abilities
    </p>
    <div class="center">
        <pre class="title">
 __       __                    ____     __                               
/\ \     /\ \       /'\_/`\    /\  _``. /\ \                              
\ \ \    \ \ \     /\      \   \ \ \/\_\\ \ \___      __    ____    ____  
 \ \ \  __\ \ \  __\ \ \__\ \   \ \ \/_/_\ \  _ `\  /'__`\ /',__\  /',__\ 
  \ \ \L\ \\ \ \L\ \\ \ \_/\ \   \ \ \L\ \\ \ \ \ \/\  __//\__, `\/\__, `\
   \ \____/ \ \____/ \ \_\\ \_\   \ \____/ \ \_\ \_\ \____\/\____/\/\____/
    \/___/   \/___/   \/_/ \/_/    \/___/   \/_/\/_/\/____/\/___/  \/___/ 

        </pre>
        <pre class="title-narrow">
         __         __         __    __                        
        /\ \       /\ \       /\ "-./  \                       
        \ \ \____  \ \ \____  \ \ \-./\ \                      
         \ \_____\  \ \_____\  \ \_\ \ \_\                     
          \/_____/   \/_____/   \/_/  \/_/                                                                                
 ______     __  __     ______     ______     ______    
/\  ___\   /\ \_\ \   /\  ___\   /\  ___\   /\  ___\   
\ \ \____  \ \  __ \  \ \  __\   \ \___  \  \ \___  \  
 \ \_____\  \ \_\ \_\  \ \_____\  \/\_____\  \/\_____\ 
  \/_____/   \/_/\/_/   \/_____/   \/_____/   \/_____/ 
        </pre>
        <div class="game">
            <span style="color: yellow;">Random Player (White)</span>
            <div class="board">
<pre class="board">
♜ ♞ ♝ ♛ ♚ ♝ ♞ ♜
♟ ♟ ♟ ♟ ♟ ♟ ♟ ♟
· · · · · · · ·
· · · · · · · ·
· · · · · · · ·
· · · · · · · ·
♙ ♙ ♙ ♙ ♙ ♙ ♙ ♙
♖ ♘ ♗ ♕ ♔ ♗ ♘ ♖</pre>
                <div class="game-over">
                    <p>GAME OVER</p>
                    <span>
                        - Outcome: Draw<br>
                        - Max moves reached: 200<br>
                        - Material White: 16<br>
                        - Material Black: 18
                    </span>
                </div>
            </div>
            <span style="color: yellow;">GPT-4o Mini (Black)</span>
        </div>
        <p class="intro">
            Can a Large Language Model play chess? Prompt it to move based on the board state, 
            hint it with legal moves, and it can make moves (though some struggle with instruction following) 
            and even explain its tactics or strategy.
            <br><br>
            But can LLMs make meaningful moves and win? 
            Let’s test them against a random player (a bot that picks legal moves randomly). 
            These Foundational Models, with their vast knowledge and reasoning abilities,
            should easily defeat a chaos monkey, right?
            <br><br>
            Let's find out ツ
        </p>
        <div class="button-container">
            <div class="custom-dropdown">
                <button class="dropbtn" onclick="toggleDropdown()">Leaderboard ▼</button>
                <div class="dropdown-content">
                    <div onclick="showPane(Screen.LEADERBOARD_NEW)">New Leaderboard</div>
                    <div onclick="showPane(Screen.LEADERBOARD_OLD)">Old Leaderboard</div>
                </div>
            </div>
            <button onclick="showPane(Screen.HOW_IT_WORKS)">How it works</button>
            <button onclick="showPane(Screen.NOTES)">Notes</button>
        </div>
        <!-- ############################ -->
        <!-- LEADERBOARD AND DESCRIPTIONS -->
        <!-- ############################ -->
        <div id="leaderboard" class="pane">
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th title="Rank">#&nbsp;&nbsp;</th>
                            <th title="Model playing as black against a Random Player">Player&nbsp;&nbsp;</th>
                            <th title="How often the player scored a win (due to checkmate or the opponent failing to make a move) in Easy mode, or difference between wins and losses in Medium mode">Wins/Diff&nbsp;&nbsp;</th>
                            <th id="draws-moves-header" title="Percentage of games without a winner in Easy mode, or average number of moves per game in Medium mode">Draws&nbsp;&nbsp;</th>
                            <th title="Number of LLM erroneous replies per 1000 moves">Mistakes&nbsp;&nbsp;</th>
                            <th title="Number of token's generated per one move">Tokens&nbsp;&nbsp;</th>
                        </tr>
                    </thead>
                    <tbody>
                        <!-- Data will be populated here -->
                    </tbody>
                </table>

            </div>
            <p class="descriptions">
                <strong>METRICS:</strong><br><br>
                <strong>- Player:</strong> Model playing as black against a Random Player.<br>
                <strong>- Wins-Losses:</strong> Difference between wins and losses as percentage of total games. Displays LLMs' proficiency in chess.<br>
                <strong>- Wins (old leaderboard):</strong> How often the player scored a win (due to checkmate or the opponent failing to make a move). Displays LLMs' proficiency in chess.<br>
                <strong>- Avg Moves:</strong> Average number of moves per game.<br>
                <strong>- Draws (old leaderboard):</strong> Percentage of games without a winner (e.g., reaching the maximum number of 200 moves or stalemate). Displays weaks' LLMs' proficiency in chess if it can't win.<br>
                <strong>- Mistakes:</strong> Number of LLM erroneous replies per 1000 moves - how often did an LLM fail to follow the instructions 
                and make a move. E.g., due to hallucinations, picking illegal moves, not conforming to the communication protocol. Shows the model's instruction-following capabilities and hallucination resistance.<br>
                <strong>- Tokens:</strong> Number of tokens generated per move. Demonstrates the model's verbosity.<br><br>
                <strong>NOTES:</strong><br><br>
                - LLMs played as black against a Random Player (as white).<br>
                - 30+ game simulations for Random Player vs. LLM.<br>
                - Bottom rows in green demonstrate how a Chess Engine (Stockfish v17) fares against a Random Player.<br>
                - 1000 simulations for Random Player vs. Chess Engine and Random vs. Random.<br>
                - <s>You see it right, LLMs scored 0 wins.</s> No longer the case, o1-mini being the 1st LLM scroging wins<br>
                - <s>Using Draws instead of Wins to evaluate LLMs' chess proficiency</s>.<br>
                - The default soritng is by Wins-Losses DESC, Draws DESC and Mistakes ASC (new leaderboard) and for older leaderboard by Wins DESC, Draws DESC and Mistakes ASC <br>
                <br>
                - Strong models (those ones winning) are judged (in Chess proficiency) by % Won, weak ones - by % Draws <br>
                - <strong>Mistakes</strong> metric gives an evaluation of LLMs' instruction-following capabilities and resistance to hallucinations (making up non-legal moves while having a list of legal moves provided in the prompt).<br>
                - Sort by <strong>Mistakes</strong> column and get a ranking by instruction-following ability (models with the least mistakes being better) <br>
            </p>
        </div>
        <!-- ############ -->
        <!-- HOW IT WORKS -->
        <!-- ############ -->
        <div id="how-it-works" class="pane" style="display: none;">
            <p class="descriptions">
                <strong>Libraries and Dependencies Used:</strong><br><br>
                - <strong>chess:</strong> A Python library for handling chess game rules and basic operations, including board representation, legal move evaluation, and game state evaluation. This is not a chess engine runnig the actual caclulation of the best move.<br>
                - <strong>Microsoft Autogen</strong> is used as a backbone for LLM communication. It also implements the interaction between a Chess Board and custom agents like GameAgent, RandomPlayerAgent, AutoReplyAgent, and others for simulating different player types.<br>
                - <strong>Stockfish</strong> - the chess engine doing the actual best move calculation, used as a referrence to demonstrate what a real chess player's peformance is.<br>
                <br>
                <strong>Workflow:</strong><br><br>
                1. The game is initialized with a chess board and two players: a Random Player (as white) and an LLM (as black).<br>
                2. The game loop runs until a termination condition is met, such as checkmate, stalemate, or reaching the maximum number of moves.<br>
                3. Each player takes turns making a move. The Random Player selects a move randomly from the list of legal moves.<br>
                4. The LLM is prompted to make a move using a structured dialog, which includes actions like getting the current board state, retrieving legal moves, and making a move.<br>
                5. The game state is updated after each move, and the board is visualized if enabled.<br>
                6. Game statistics are generated and stored at the end of the game.<br>
                <br>
                <strong>Dialog:</strong><br><br>
                Here is an example of a dialog that prompts a model to make a move:<br>
            </p>
            <pre class="snippet">
<span style="color:green">Proxy (to Player_Black):</span>
You are a professional chess player and you play as black. Now is your turn to make a move. Before making a move you can pick one of the following actions:
- 'get_current_board' to get the schema and current status of the board
- 'get_legal_moves' to get a UCI formatted list of available moves
- 'make_move &lt;UCI formatted move&gt;' when you are ready to complete your turn (e.g., 'make_move e2e4')
Respond with the action.

<span style="color:green">Player_Black (to Proxy):</span>
get_current_board

<span style="color:green">Proxy (to Player_Black):</span>
<span style="font-family: Chess;">♞ ♝ ♛ ♚ ♝ ♞ ♜ ♜
♟ ♟ ♟ ♟ ♟ ♟ ♟ ♟
· · · · · · · ·
· · · · · · · ·
· · · · · · · ·
· · · · · · · ·
♙ ♙ ♙ ♙ ♙ ♙ ♙ ♙
♖ ♘ ♗ ♕ ♔ ♗ ♘ ♖
</span>

<span style="color:green">Player_Black (to Proxy):</span>
get_legal_moves

<span style="color:green">Proxy (to Player_Black):</span>
a7a6, b7b6, c7c6, d7d6, e7e6, f7f6, g7g6, h7h6, a7a5, b7b5, c7c5, d7d5, e7e5, f7f5, g7g5, h7h5

<span style="color:green">Player_Black (to Proxy):</span>
make_move e7e5

<span style="color:green">Proxy (to Player_Black):</span>
Move made, switching player
            </pre>
            <p class="descriptions">
                1 move - 1 dialog. The dialog is limmited to 10 turns (10 pairs of Proxy/Agent Request/Response messages). A maximum of 3 mistakes (not conforming to 
                communication notation, picking wrong action or wrong move) are allowed per dialog. 
                The game is terminanted and LLM is given a loss if the max turns OR of number of LLM mistakes is reached in the given dialog.
            </p>
        </div>
        <!-- ############ -->
        <!-- NOTES        -->
        <!-- ############ -->
        <div id="considerations" class="pane" style="display: none;">
        </div>
        <a class="gh" href="https://github.com/maxim-saplin/llm_chess/" target="_blank">
            <img src="icons/gh.png" alt="GitHub Icon">
            Project's GitHub
        </a>
    <p id="mistakes"></p>
    <p id="completion-tokens"></p>
</div>
    <div id="popup" style="display: none;">
        <p id="total-games"></p>
        <p id="wins"></p>
        <p id="losses"></p>
        <p id="wins_minus_losses"></p>
        <p id="draws"></p> 
        <p id="average-moves"></p>
        <p id="material-diff"></p>
        <p id="mistakes-per-1000moves"></p>
        <p id="completion-tokens-black-per-move"></p>
    </div>
</body>
</html>
