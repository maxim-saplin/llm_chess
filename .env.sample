## Environment Configuration Sample
## This file contains configuration for different LLM providers
## Copy this file to .env and uncomment/edit the sections you need
## Note: _W and _B suffixes mean White and Black player
## AG2 providers can be easily added, AG2 docs and change utils.py to add the new provider

## Azure OpenAI

MODEL_KIND_W=azure
AZURE_OPENAI_VERSION_W=2024-02-15-preview
AZURE_OPENAI_ENDPOINT_W=https://xyz.openai.azure.com
AZURE_OPENAI_KEY_W=28e391234c5e4ab7b0ac440f6c330xyz
AZURE_OPENAI_DEPLOYMENT_W=gpt-4o-mini

## OpenAI Compatibe API endpoint with custom API base (for self-hosted models or alternative providers)

MODEL_KIND_B="ocal
LOCAL_MODEL_NAME_B=llama 3.1 8B
LOCAL_BASE_URL_B=localhost:1234
LOCAL_API_KEY_B=your_local_api_key

## OpenAI

# MODEL_KIND_B=openai
# OPENAI_MODEL_NAME_B=gpt-4
# OPENAI_API_KEY_B=your_openai_api_key

## Google

# MODEL_KIND_B=gemini
# GEMINI_MODEL_NAME_B=gemini-pro
# GEMINI_API_KEY_B=your_google_genai_key

## Anthropic

# MODEL_KIND_B=anthropic
# ANTHROPIC_MODEL_NAME_B=claude-3-5-sonnet-20240620
# ANTHROPIC_API_KEY_B=your_anthropic_api_key

## x.ai/Grok
# MODEL_KIND_W=xai
# XAI_MODEL_NAME_W=xai-model-1
# XAI_API_KEY_W=your_xai_api_key_here
