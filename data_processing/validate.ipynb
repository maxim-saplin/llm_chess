{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas Jinja2 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from aggregate_logs_to_csv import aggregate_models_to_csv, MODEL_OVERRIDES\n",
    "from aggr_logs_to_plain_csv import aggregate_logs_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Aggregate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_DIR = \"_logs/no_reflection\"\n",
    "AGGREGATE_CSV = os.path.join(LOGS_DIR, \"aggregate_models.csv\")\n",
    "REFINED_CSV = \"data_processing/refined.csv\"\n",
    "\n",
    "aggregate_models_to_csv(\"../_logs/no_reflection\",\"aggr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model_name  total_games  black_llm_wins  white_rand_wins  draws  black_llm_wins_percent  black_llm_draws_percent  llm_total_moves  llm_wrong_actions  llm_wrong_moves  llm_avg_material  llm_std_dev_material  rand_avg_material  rand_std_dev_material  material_diff_llm_minus_rand  material_diff_llm_minus_rand_per_100moves  wrong_actions_per_100moves  wrong_moves_per_100moves  wrong_actions_per_1000moves  wrong_moves_per_1000moves  mistakes_per_1000moves  std_dev_wrong_actions_per_1000moves  std_dev_wrong_moves_per_1000moves  std_dev_mistakes_per_1000moves  average_moves  std_dev_moves  completion_tokens_black  completion_tokens_black_per_move  min_moves  max_moves  prompt_tokens_black  total_tokens_black  moe_material_diff  moe_avg_moves  moe_wrong_actions_per_1000moves  moe_wrong_moves_per_1000moves  moe_mistakes_per_1000moves\n",
      "         anthropic.claude-v3-5-sonnet           30               0                8     22                0.000000                73.333333             5148                  0               12         15.800000              9.918287          22.500000              11.840171                     -6.700000                                  -3.695372                    0.000000                  1.465774                     0.000000                  14.657738               14.657738                             0.000000                          55.735992                       55.735992     171.600000      55.148452                   417373                         81.074786         10        200              2997738             3415111           3.674824      19.734620                         0.000000                      19.944868                   19.944868\n",
      "      anthropic.claude-v3-5-sonnet-v1           60               4                8     48                6.666667                80.000000            11003                  0                3         13.200000              8.297028          17.366667               9.425833                     -4.166667                                  -1.932540                    0.000000                  0.166667                     0.000000                   1.666667                1.666667                             0.000000                          12.909944                       12.909944     183.383333      40.117662                   884906                         80.424066         30        200              6420741             7305647           3.004864      10.151169                         0.000000                       3.266667                    3.266667\n",
      "      anthropic.claude-v3-5-sonnet-v2           60               2                5     53                3.333333                88.333333            11292                  0                8         10.816667              7.740476          13.833333               8.843587                     -3.016667                                  -0.511342                    0.000000                  0.298287                     0.000000                   2.982872                2.982872                             0.000000                          18.027529                       18.027529     188.200000      37.124984                  1025929                         90.854499         22        200              6510330             7536259           2.559979       9.393917                         0.000000                       4.561594                    4.561594\n",
      "            anthropic.claude-v3-haiku           40               0               40      0                0.000000                 0.000000             1334                  7                4         36.725000              3.389180          37.150000               3.731708                     -0.425000                                  -1.171085                    1.320346                  1.354167                    13.203463                  13.541667               26.745130                            56.506168                          64.264619                       99.020848      33.350000      25.662054                   280994                        210.640180          2         98              2052970             2333964           1.073278       7.952753                        17.511443                      19.915812                   30.686879\n",
      "             anthropic.claude-v3-opus           30               0                5     25                0.000000                83.333333             4968                  1                7         15.633333             10.479811          21.633333              10.189526                     -6.000000                                  -3.349804                    0.185185                  0.745763                     1.851852                   7.457635                9.309486                            10.143010                          26.144328                       34.402708     165.600000      66.459010                   361980                         72.862319         18        200              2833235             3195215           3.159008      23.782051                         3.629630                       9.355628                   12.310851\n",
      "                        deepseek-chat           70               0               68      2                0.000000                 2.857143             4043                 10              180         32.171429              9.020060          30.528571               8.534196                      1.642857                                   3.527257                    0.197791                  9.634065                     1.977915                  96.340648               98.318562                             8.077225                          89.778101                       88.872150      57.757143      50.628638                   998322                        246.926045          8        200              2614032             3612354           1.424718      11.860508                         1.892210                      21.031850                   20.819617\n",
      "    deepseek-r1-distill-qwen-14b@q8_0           30               0               30      0                0.000000                 0.000000               78                 82                8         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                  117.500000                 11.666667                  1175.000000                 116.666667             1291.666667                           460.275405                         333.045853                      354.061005       2.600000       1.069966                   239699                       3073.064103          2          6               175575              415274           0.000000       0.382882                       164.707438                     119.178928                  126.699104\n",
      "  deepseek-r1-distill-qwen-32b@q4_k_m          108               0              107      1                0.000000                 0.925926              377                246               49         39.000000              0.000000          38.990741               0.096225                      0.009259                                   0.092593                   83.294753                 13.171296                   832.947531                 131.712963              964.660494                           522.685503                         259.538837                      469.866741       3.490741       1.886971                   820049                       2175.196286          1         10               720085             1540134           0.018148       0.355885                        98.579055                      48.949307                   88.617378\n",
      "                    deepseek-reasoner           31               7               18      6               22.580645                19.354839             2845                  9               44         21.935484             13.971245          10.806452              14.005759                     11.129032                                  17.038444                    0.610575                  4.682528                     6.105747                  46.825283               52.931029                            21.376097                          91.350847                       93.189127      91.774194      65.017285                 13044247                       4584.972583          4        200               901267            13945514           3.603464      22.887800                         7.524950                      32.157909                   32.805032\n",
      "                 gemini-1.5-flash-001           30               0               20     10                0.000000                33.333333             2524                 18               36         29.266667             12.119899          35.666667               6.047703                     -6.400000                                  -3.314049                   11.457672                 22.915344                   114.576720                 229.153439              343.730159                           112.800075                         225.600151                      338.400226      84.133333      93.697508                    50265                         19.914818          4        200              1234960             1285225           3.127540      33.529223                        40.364989                      80.729977                  121.094966\n",
      "          gemini-1.5-pro-preview-0409           40               0               37      3                0.000000                 7.500000             2626                 14               71         29.750000              9.662908          33.075000               7.169692                     -3.325000                                  -3.836997                    0.473273                  7.771718                     4.732730                  77.717178               82.449908                             8.100324                          76.131345                       72.662878      65.650000      59.733833                    35145                         13.383473          5        200              1665689             1700834           2.355335      18.511707                         2.510316                      23.593348                   22.518459\n",
      "                 gemini-2.0-flash-exp           30               0               28      2                0.000000                 6.666667             2576                  0               81         26.933333             12.250076          27.166667              12.512293                     -0.233333                                  -1.219356                    0.000000                 11.739474                     0.000000                 117.394744              117.394744                             0.000000                         131.059012                      131.059012      85.866667      73.623335                   433155                        168.150233          6        200              1720039             2153194           1.881101      26.345772                         0.000000                      46.898865                   46.898865\n",
      "  gemini-2.0-flash-thinking-exp-01-21           33               0               31      2                0.000000                 6.060606             1341                  7                1         33.212121              6.989982          33.727273               6.969903                     -0.515152                                  -0.768642                    4.962982                  0.061843                    49.629821                   0.618429               50.248250                           260.958497                           3.552605                      260.861371      40.636364      25.123219                    23829                         17.769575          2        119               625305              649134           1.841571       8.571847                        89.037005                       1.212121                   89.003867\n",
      "   gemini-2.0-flash-thinking-exp-1219           30               0               30      0                0.000000                 0.000000               70                 89                1         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                  138.611111                  0.555556                  1386.111111                   5.555556             1391.666667                           302.830938                          30.429031                      283.780918       2.333333       0.922266                    50718                        724.542857          2          6               224271              274989           0.000000       0.330029                       108.366660                      10.888889                  101.549697\n",
      "                gemma-2-27b-it@q6_k_l           30               0               22      8                0.000000                26.666667             3268                  8               52         25.466667             11.717165          26.333333              10.306788                     -0.866667                                   1.339260                    0.383141                  4.807826                     3.831408                  48.078261               51.909669                             8.092186                          69.585084                       69.635666     108.933333      70.564196                   179885                         55.044370         10        200              2028385             2208270           2.669171      25.251073                         2.895751                      24.900703                   24.918803\n",
      "                   gemma-2-9b-it-8bit           30               0               26      4                0.000000                13.333333             2075                 45               31         32.000000              9.180189          34.133333               7.758125                     -2.133333                                  -3.055976                   16.366923                  7.124054                   163.669227                  71.240543              234.909770                           372.225541                         113.887523                      378.257458      69.166667      72.833340                   120608                         58.124337          2        200              1201066             1321674           1.804545      26.063076                       133.199199                      40.754127                  135.357693\n",
      "                         gemma2-9b-it           35               0               35      0                0.000000                 0.000000              516                 83               22         38.714286              1.045197          38.314286               2.272229                      0.400000                                   1.161304                   41.480914                  6.174549                   414.809142                  61.745489              476.554631                           479.257861                          85.575010                      463.030923      14.742857      15.897360                    10432                         20.217054          2         88               342837              353269           0.563612       5.266803                       158.778354                      28.351041                  153.402361\n",
      "                    gpt-35-turbo-0125           30               0               30      0                0.000000                 0.000000               86                 90                0         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                  128.500000                  0.000000                  1285.000000                   0.000000             1285.000000                           404.319351                           0.000000                      404.319351       2.866667       1.870521                     7054                         82.023256          2         10                89137               96191           0.000000       0.669358                       144.683822                       0.000000                  144.683822\n",
      "                    gpt-35-turbo-0301           30               0               30      0                0.000000                 0.000000               68                 90                0         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                  140.000000                  0.000000                  1400.000000                   0.000000             1400.000000                           259.309428                           0.000000                      259.309428       2.266667       0.691492                     4560                         67.058824          2          4                57543               62103           0.000000       0.247447                        92.792687                       0.000000                   92.792687\n",
      "                    gpt-35-turbo-0613           30               0               30      0                0.000000                 0.000000              124                 90                0         39.000000              0.000000          38.966667               0.182574                      0.033333                                   0.277778                  105.166667                  0.000000                  1051.666667                   0.000000             1051.666667                           527.393286                           0.000000                      527.393286       4.133333       2.825174                    11610                         93.629032          2         12               129031              140641           0.065333       1.010976                       188.725264                       0.000000                  188.725264\n",
      "                    gpt-35-turbo-1106           30               0               30      0                0.000000                 0.000000              108                 88                2         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                  113.027778                  0.888889                  1130.277778                   8.888889             1139.166667                           506.327224                          34.942025                      491.947368       3.600000       2.429701                     5219                         48.324074          2         10                49156               54375           0.000000       0.869457                       181.186870                      12.503843                  176.041105\n",
      "                           gpt-4-0613           17               0                2     15                0.000000                88.235294             3232                  0                0         14.764706              9.437488          20.411765               7.211612                     -5.647059                                  -3.106663                    0.000000                  0.000000                     0.000000                   0.000000                0.000000                             0.000000                           0.000000                        0.000000     190.117647      39.979498                    21268                          6.580446         35        200               548490              569758           4.433767      19.005047                         0.000000                       0.000000                    0.000000\n",
      "                       gpt-4-32k-0613           11               0                1     10                0.000000                90.909091             2157                  0                0         12.909091              7.272614          17.818182               6.193839                     -4.909091                                  -2.715981                    0.000000                  0.000000                     0.000000                   0.000000                0.000000                             0.000000                           0.000000                        0.000000     196.090909      12.964988                    14164                          6.566528        157        200               369433              383597           5.275506       7.661818                         0.000000                       0.000000                    0.000000\n",
      "               gpt-4-turbo-2024-04-09           30               0                2     28                0.000000                93.333333             5786                  0                0         15.433333              8.033050          20.800000               9.654015                     -5.366667                                  -3.062648                    0.000000                  0.000000                     0.000000                   0.000000                0.000000                             0.000000                           0.000000                        0.000000     192.866667      29.930648                    34906                          6.032838         45        200              2439800             2474706           3.719412      10.710545                         0.000000                       0.000000                    0.000000\n",
      "                    gpt-4o-2024-05-13           60               0               12     48                0.000000                80.000000            11057                  1               16         13.633333              7.955313          17.350000               7.049041                     -3.716667                                  -1.527760                    0.008333                  0.346151                     0.083333                   3.461511                3.544844                             0.645497                          13.806160                       13.800001     184.283333      37.280927                   346468                         31.334720         32        200              5019535             5366003           1.914112       9.433376                         0.163333                       3.493441                    3.491882\n",
      "                    gpt-4o-2024-08-06           60               1                9     50                1.666667                83.333333            11214                  0                1         14.483333              7.349603          19.333333               8.711315                     -4.850000                                  -3.206580                    0.000000                  0.015723                     0.000000                   0.157233                0.157233                             0.000000                           1.217919                        1.217919     186.900000      31.814451                    86384                          7.703228         51        200              4649382             4735766           2.569851       8.050167                         0.000000                       0.308176                    0.308176\n",
      "                    gpt-4o-2024-11-20           71               3                6     62                4.225352                87.323944            13470                  1                1         11.901408              8.055442          19.901408               8.637385                     -8.000000                                  -4.177047                    0.007042                  0.007042                     0.070423                   0.070423                0.140845                             0.593391                           0.593391                        0.833166     189.718310      32.637482                   681249                         50.575278         29        200              6229300             6910549           2.499409       7.591779                         0.138028                       0.138028                    0.193802\n",
      "               gpt-4o-mini-2024-07-18           30               0               12     18                0.000000                60.000000             4481                 13               24         20.433333              9.339140          24.866667               9.179187                     -4.433333                                  -3.865782                    0.470145                  3.108335                     4.701452                  31.083346               35.784798                            11.075969                          77.402457                       77.223721     149.366667      70.243165                   484917                        108.216246         10        200              2438163             2923080           3.093589      25.136194                         3.963485                      27.698114                   27.634154\n",
      "              granite-3.1-8b-instruct           30               0               30      0                0.000000                 0.000000              126                 47               12         38.966667              0.182574          39.000000               0.000000                     -0.033333                                  -0.416667                   44.750000                  9.166667                   447.500000                  91.666667              539.166667                           471.811490                         223.553246                      490.543476       4.200000       2.483046                    59110                        469.126984          2         10               377120              436230           0.065333       0.888547                       168.835573                      79.997502                  175.538729\n",
      "                          grok-2-1212           49               2               32     15                4.081633                30.612245             5593                  1               93         25.326531             11.336497          22.387755               9.677759                      2.938776                                   4.224505                    0.051020                  3.228055                     0.510204                  32.280546               32.790750                             3.571429                          33.294808                       33.760289     114.142857      67.887161                   370417                         66.228679         26        200              2811967             3182384           2.520265      19.008405                         1.000000                       9.322546                    9.452881\n",
      "                internlm3-8b-instruct           30               0               30      0                0.000000                 0.000000              108                 15               39         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                   16.666667                 41.250000                   166.666667                 412.500000              579.166667                           401.147779                         538.546495                      593.139053       3.600000       1.922642                   166741                       1543.898148          2          8               690605              857346           0.000000       0.688009                       143.548889                     192.716388                  212.252084\n",
      "                      llama-2-7b-chat           30               0               30      0                0.000000                 0.000000               64                 88                2         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                  142.500000                  2.500000                  1425.000000                  25.000000             1450.000000                           238.077791                         100.644475                      190.281099       2.133333       0.507416                     7444                        116.312500          2          4                75064               82508           0.000000       0.181577                        85.195043                      36.015163                   68.091217\n",
      "             llama-3-70b-instruct-awq           30               0               15     15                0.000000                50.000000             4449                  2               41         21.566667             10.129109          26.966667               7.716902                     -5.400000                                  -2.185616                    0.060606                  2.227814                     0.606061                  22.278143               22.884204                             3.319531                          41.243450                       41.176519     148.300000      62.428525                   185118                         41.608901         14        200              2349787             2534905           3.086325      22.339761                         1.187879                      14.758779                   14.734828\n",
      "                 llama-3.1-8b-instant           60               0               60      0                0.000000                 0.000000             1754                 27              146         36.616667              4.329997          37.533333               2.977126                     -0.916667                                  -2.980310                    3.076102                 14.210738                    30.761016                 142.107380              172.868397                            57.328862                         111.870944                      134.394974      29.233333      21.588106                   292050                        166.505131          6         98              1635437             1927487           0.980876       5.462545                        14.506204                      28.307254                   34.006620\n",
      "         llama-3.2-90b-vision-preview            7               0                5      2                0.000000                28.571429              730                  1               14         24.142857             13.643418          32.428571               9.795529                     -8.285714                                  -5.466511                    0.097847                 12.793857                     0.978474                 127.938568              128.917041                             2.588798                         195.528622                      194.877711     104.285714      82.900974                    24475                         33.527397          6        200               399909              424384           7.707209      61.413901                         1.917808                     144.849630                  144.367429\n",
      "                        llama-3.3-70b           42               0               38      4                0.000000                 9.523810             2886                  2              100         30.904762             11.604897          33.452381               8.121643                     -2.547619                                  -1.265137                    0.330688                 10.734968                     3.306878                 107.349677              110.656556                            15.279171                         127.192508                      129.084107      68.714286      69.413320                   297205                        102.981635          4        200              2032359             2329564           1.745939      20.992987                         4.620949                      38.467411                   39.039496\n",
      "              llama-3.3-70b-versatile            2               0                2      0                0.000000                 0.000000               60                  0                6         37.000000              2.828427          39.000000               0.000000                     -2.000000                                  -5.000000                    0.000000                 11.250000                     0.000000                 112.500000              112.500000                             0.000000                          53.033009                       53.033009      30.000000      14.142136                     7018                        116.966667         20         40                43372               50390           3.920000      19.600000                         0.000000                      73.500000                   73.500000\n",
      "                       llama3-8b-8192           60               0               60      0                0.000000                 0.000000              902                104               66         38.200000              2.097618          38.683333               1.065510                     -0.483333                                  -1.416967                   20.694153                  8.971030                   206.941531                  89.710304              296.651835                           220.415794                          93.519498                      208.911913      15.033333      10.541229                    51432                         57.019956          4         50               749595              801027           0.552198       2.667299                        55.772891                      23.663698                   52.862007\n",
      "                          llama3.1-8b           90               0               87      3                0.000000                 3.333333             2436                 44              188         37.200000              3.736248          37.833333               2.545099                     -0.633333                                  -1.574541                    3.503988                 12.664664                    35.039880                 126.646638              161.686518                            55.908533                         113.698417                      127.446990      27.066667      22.241170                   394879                        162.101396          4        100              1995033             2389912           0.803128       4.595073                        11.550822                      23.490336                   26.330821\n",
      "      meta-llama-3.1-8b-instruct-fp16           30               0               30      0                0.000000                 0.000000              830                 19               61         36.733333              4.093168          37.000000               3.393706                     -0.266667                                   0.463016                    7.235502                 13.547422                    72.355016                 135.474221              207.829237                           158.436219                         149.216987                      226.540912      27.666667      22.713103                    59644                         71.860241          4         84               577065              636709           1.757940       8.127780                        56.695673                      53.396613                   81.066624\n",
      "           ministral-8b-instruct-2410           30               0               30      0                0.000000                 0.000000              282                 56               34         38.766667              0.773854          38.600000               1.714039                      0.166667                                   1.388889                   45.351787                 15.281205                   453.517871                 152.812049              606.329920                           568.294733                         291.704107                      524.116634       9.400000       6.911260                    20336                         72.113475          2         26               179727              200063           0.564501       2.473163                       203.361658                     104.384974                  187.552729\n",
      "       mistral-nemo-12b-instruct-2407           30               0               30      0                0.000000                 0.000000              202                 79               11         38.766667              0.678911          38.666667               1.647011                      0.100000                                   1.375000                   73.394841                  4.250000                   733.948413                  42.500000              776.448413                           584.665140                         105.915775                      542.847323       6.733333       5.132273                     9635                         47.698020          2         20               127958              137593           0.509115       1.836560                       209.219733                      37.901473                  194.255420\n",
      "          mistral-small-instruct-2409           30               0               30      0                0.000000                 0.000000              272                 58               32         38.866667              0.345746          38.833333               0.592093                      0.033333                                   0.431818                   36.549603                 12.791847                   365.496032                 127.918470              493.414502                           440.127466                         172.885223                      381.098770       9.066667       5.323554                    24002                         88.242647          2         22               216674              240676           0.175392       1.905009                       157.497591                      61.866182                  136.374443\n",
      "                   mixtral-8x7b-32768           20               0               20      0                0.000000                 0.000000               40                 60                0         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                  150.000000                  0.000000                  1500.000000                   0.000000             1500.000000                             0.000000                           0.000000                        0.000000       2.000000       0.000000                      660                         16.500000          2          2                10320               10980           0.000000       0.000000                         0.000000                       0.000000                    0.000000\n",
      "                   o1-mini-2024-09-12           30               9                6     15               30.000000                50.000000             4282                  2                8         17.666667             12.208910           7.033333              11.330409                     10.633333                                   9.487098                    0.094508                  0.334929                     0.945083                   3.349288                4.294371                             3.685603                           9.785673                       11.991503     142.733333      61.450812                  5228905                       1221.136151         28        200              1020768             6249673           3.159683      21.989891                         1.318876                       3.501758                    4.291104\n",
      "                o1-preview-2024-09-12           30              14                3     13               46.666667                43.333333             3744                  4               10         17.800000             14.641462           4.033333               8.066462                     13.766667                                  18.250560                    0.292315                  0.636405                     2.923152                   6.364051                9.287203                             9.699130                          19.139350                       28.530703     124.800000      61.522858                  9959309                       2660.071848         20        200              1184284            11143593           4.335777      22.015672                         3.470789                       6.848928                   10.209581\n",
      "                                phi-4           30               0               30      0                0.000000                 0.000000              232                 44               46         39.000000              0.000000          39.000000               0.000000                      0.000000                                   0.000000                   26.484848                 23.267316                   264.848485                 232.673160              497.521645                           286.038611                         248.578985                      216.600283       7.733333       4.630732                    77382                        333.543103          4         22               236743              314125           0.000000       1.657086                       102.357602                      88.952847                   77.509416\n",
      "                  qwen-max-2025-01-25           13               0                0     13                0.000000               100.000000             2600                  0                0         16.230769              5.418392          21.000000               8.698659                     -4.769231                                  -2.384615                    0.000000                  0.000000                     0.000000                   0.000000                0.000000                             0.000000                           0.000000                        0.000000     200.000000       0.000000                    15905                          6.117308        200        200              1041952             1057857           4.883154       0.000000                         0.000000                       0.000000                    0.000000\n",
      "qwen2.5-14b-instruct-1m@q4_k_m@q4_k_m            3               0                1      2                0.000000                66.666667              500                  0                3         16.333333             10.066446          27.000000               8.000000                    -10.666667                                  -6.666667                    0.000000                  1.000000                     0.000000                  10.000000               10.000000                             0.000000                          17.320508                       17.320508     166.666667      57.735027                   107395                        214.790000        100        200               308071              415466           9.422507      65.333333                         0.000000                      19.600000                   19.600000\n",
      "            qwen2.5-14b-instruct@q8_0           30               0               30      0                0.000000                 0.000000              398                 29               59         38.566667              1.040004          38.400000               1.904622                      0.166667                                   0.319264                   15.693122                 21.267376                   156.931217                 212.673761              369.604978                           267.142618                         200.525842                      306.563633      13.266667      10.027319                    59951                        150.630653          2         42               303196              363147           0.637945       3.588230                        95.595758                      71.757251                  109.702387\n",
      "                 qwen2.5-72b-instruct           10               0               10      0                0.000000                 0.000000              446                  4               26         34.600000              6.345602          34.400000               5.719363                      0.200000                                   0.474514                    1.323764                 12.869945                    13.237640                 128.699454              141.937094                            26.669048                         145.062094                      146.355387      44.600000      33.559897                   103378                        231.789238          6        100               304144              407522           2.829771      20.800639                        16.529647                      89.910417                   90.712009\n",
      "              qwen2.5-vl-72b-instruct           10               0               10      0                0.000000                 0.000000              244                  1               26         35.900000              5.258855          38.300000               1.567021                     -2.400000                                  -5.565176                    0.714286                 14.419192                     7.142857                 144.191919              151.334776                            22.587698                         110.075216                      112.274531      24.400000      15.966632                    88102                        361.073770          8         54               208793              296895           2.377272       9.896221                        14.000000                      68.225325                   69.588475\n",
      "               qwq-32b-preview@q4_k_m           30               0               30      0                0.000000                 0.000000              239                 44               17         38.866667              0.571346          38.966667               0.182574                     -0.100000                                  -1.306818                   30.863817                  9.735570                   308.638167                  97.355700              405.993867                           410.368000                         197.681270                      439.585866       7.966667       4.845783                   695012                       2908.000000          2         22              1406225             2101237           0.217364       1.734041                       146.848303                      70.739334                  157.303782\n",
      "                   sky-t1-32b-preview           30               0               30      0                0.000000                 0.000000              415                  9               59         38.766667              0.773854          38.800000               0.761124                     -0.033333                                  -0.080860                    2.457071                 18.510432                    24.570707                 185.104316              209.675023                            66.269383                         173.926697                      169.607361      13.833333       9.299920                   504706                       1216.159036          2         46               932760             1437466           0.345072       3.327934                        23.714194                      62.238869                   60.693215\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"aggr.csv\"\n",
    "# CSV cols:\n",
    "# model_name,total_games,black_llm_wins,white_rand_wins,draws,black_llm_wins_percent,black_llm_draws_percent,llm_total_moves,llm_wrong_actions,llm_wrong_moves,llm_avg_material,llm_std_dev_material,rand_avg_material,rand_std_dev_material,material_diff_llm_minus_rand,material_diff_llm_minus_rand_per_100moves,wrong_actions_per_100moves,wrong_moves_per_100moves,wrong_actions_per_1000moves,wrong_moves_per_1000moves,mistakes_per_1000moves,std_dev_wrong_actions_per_1000moves,std_dev_wrong_moves_per_1000moves,std_dev_mistakes_per_1000moves,average_moves,std_dev_moves,completion_tokens_black,completion_tokens_black_per_move,min_moves,max_moves,prompt_tokens_black,total_tokens_black,moe_material_diff,moe_avg_moves,moe_wrong_actions_per_1000moves,moe_wrong_moves_per_1000moves,moe_mistakes_per_1000moves\n",
    "\n",
    "df_aggr = pd.read_csv(csv_file_path)\n",
    "print(df_aggr.to_string(index=False))\n",
    "\n",
    "# selected_columns = df_aggr[[\"model_name\", \"total_games\", \"wrong_actions_per_100moves\", \"wrong_moves_per_100moves\", \"min_moves\", \"max_moves\", \"average_moves\", \"std_dev_moves\"]]\n",
    "\n",
    "# Print the DataFrame as a properly tabbed table with headers\n",
    "# print(selected_columns.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Flattened (Plain) CSV with Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>model</th>\n",
       "      <th>time_started</th>\n",
       "      <th>winner</th>\n",
       "      <th>reason</th>\n",
       "      <th>number_of_moves</th>\n",
       "      <th>player_white_name</th>\n",
       "      <th>player_white_wrong_moves</th>\n",
       "      <th>player_white_wrong_actions</th>\n",
       "      <th>player_white_reflections_used</th>\n",
       "      <th>...</th>\n",
       "      <th>material_count_black</th>\n",
       "      <th>player_black_name</th>\n",
       "      <th>player_black_wrong_moves</th>\n",
       "      <th>player_black_wrong_actions</th>\n",
       "      <th>player_black_reflections_used</th>\n",
       "      <th>player_black_reflections_used_before_board</th>\n",
       "      <th>player_black_model</th>\n",
       "      <th>black_model_prompt_tokens</th>\n",
       "      <th>black_model_completion_tokens</th>\n",
       "      <th>black_model_total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../_logs/no_reflection/2025-01-19_anthropic.cl...</td>\n",
       "      <td>anthropic.claude-v3-5-sonnet-v2</td>\n",
       "      <td>2025.01.19_17:52</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Max moves reached</td>\n",
       "      <td>200</td>\n",
       "      <td>Random_Player</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Player_Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>anthropic.claude-v3-5-sonnet-v2</td>\n",
       "      <td>113375</td>\n",
       "      <td>18006</td>\n",
       "      <td>131381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../_logs/no_reflection/2025-01-19_anthropic.cl...</td>\n",
       "      <td>anthropic.claude-v3-5-sonnet-v2</td>\n",
       "      <td>2025.01.19_15:59</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Max moves reached</td>\n",
       "      <td>200</td>\n",
       "      <td>Random_Player</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Player_Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>anthropic.claude-v3-5-sonnet-v2</td>\n",
       "      <td>119092</td>\n",
       "      <td>18737</td>\n",
       "      <td>137829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  ../_logs/no_reflection/2025-01-19_anthropic.cl...   \n",
       "1  ../_logs/no_reflection/2025-01-19_anthropic.cl...   \n",
       "\n",
       "                             model      time_started winner  \\\n",
       "0  anthropic.claude-v3-5-sonnet-v2  2025.01.19_17:52   NONE   \n",
       "1  anthropic.claude-v3-5-sonnet-v2  2025.01.19_15:59   NONE   \n",
       "\n",
       "              reason  number_of_moves player_white_name  \\\n",
       "0  Max moves reached              200     Random_Player   \n",
       "1  Max moves reached              200     Random_Player   \n",
       "\n",
       "   player_white_wrong_moves  player_white_wrong_actions  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "\n",
       "   player_white_reflections_used  ...  material_count_black  \\\n",
       "0                              0  ...                    11   \n",
       "1                              0  ...                     8   \n",
       "\n",
       "   player_black_name  player_black_wrong_moves  player_black_wrong_actions  \\\n",
       "0       Player_Black                         1                           0   \n",
       "1       Player_Black                         0                           0   \n",
       "\n",
       "  player_black_reflections_used  player_black_reflections_used_before_board  \\\n",
       "0                             0                                           0   \n",
       "1                             0                                           0   \n",
       "\n",
       "                player_black_model  black_model_prompt_tokens  \\\n",
       "0  anthropic.claude-v3-5-sonnet-v2                     113375   \n",
       "1  anthropic.claude-v3-5-sonnet-v2                     119092   \n",
       "\n",
       "   black_model_completion_tokens black_model_total_tokens  \n",
       "0                          18006                   131381  \n",
       "1                          18737                   137829  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_logs_to_dataframe(logs_path, output_csv, model_dict):\n",
    "    \"\"\"\n",
    "    Process logs into a DataFrame, substitute model names, and return the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        logs_path (str): Path to the logs directory.\n",
    "        output_csv (str): Path to save the intermediate CSV file.\n",
    "        model_dict (dict): Dictionary for substituting model names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with substituted model names.\n",
    "    \"\"\"\n",
    "    # Aggregate logs into a CSV\n",
    "    aggregate_logs_to_csv(logs_path, output_csv)\n",
    "\n",
    "    # Read the aggregated CSV into a DataFrame\n",
    "    df_plain = pd.read_csv(output_csv)\n",
    "\n",
    "    # Insert the 'model' column based on 'player_black_model'\n",
    "    df_plain.insert(df_plain.columns.get_loc(\"path\") + 1, \"model\", df_plain[\"player_black_model\"])\n",
    "\n",
    "    # Replace model names in the DataFrame using model_dict values\n",
    "    def substitute_model_names(df, model_dict):\n",
    "        def get_correct_model_name(row):\n",
    "            key = next((k for k in model_dict if os.path.dirname(row.path).endswith(k)), None)\n",
    "            return model_dict[key] if key else row[\"model\"]  # Default to the original model if no match is found\n",
    "\n",
    "        df[\"model\"] = df.apply(get_correct_model_name, axis=1)\n",
    "\n",
    "    # Apply the substitution logic\n",
    "    substitute_model_names(df_plain, model_dict)\n",
    "\n",
    "    return df_plain\n",
    "\n",
    "# Example usage\n",
    "df_plain = process_logs_to_dataframe(\"../_logs/no_reflection\", \"plain.csv\", MODEL_OVERRIDES)\n",
    "display(df_plain.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Aggr to Aggr-from-Plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total_games in df_aggr: 1902\n",
      "Sum of total_games in aggregates: 1902\n",
      "Columns in df_aggr:\n",
      "['model_name', 'total_games', 'black_llm_wins', 'white_rand_wins', 'draws', 'black_llm_wins_percent', 'black_llm_draws_percent', 'llm_total_moves', 'llm_wrong_actions', 'llm_wrong_moves', 'llm_avg_material', 'llm_std_dev_material', 'rand_avg_material', 'rand_std_dev_material', 'material_diff_llm_minus_rand', 'material_diff_llm_minus_rand_per_100moves', 'wrong_actions_per_100moves', 'wrong_moves_per_100moves', 'wrong_actions_per_1000moves', 'wrong_moves_per_1000moves', 'mistakes_per_1000moves', 'std_dev_wrong_actions_per_1000moves', 'std_dev_wrong_moves_per_1000moves', 'std_dev_mistakes_per_1000moves', 'average_moves', 'std_dev_moves', 'completion_tokens_black', 'completion_tokens_black_per_move', 'min_moves', 'max_moves', 'prompt_tokens_black', 'total_tokens_black', 'moe_material_diff', 'moe_avg_moves', 'moe_wrong_actions_per_1000moves', 'moe_wrong_moves_per_1000moves', 'moe_mistakes_per_1000moves']\n",
      "Columns in aggregates_from_plain:\n",
      "['model', 'total_games', 'black_llm_wins', 'white_rand_wins', 'draws', 'sum_wrong_actions', 'sum_wrong_moves', 'sum_moves', 'min_moves', 'max_moves', 'average_moves', 'std_dev_moves', 'average_material_count_white', 'std_dev_material_count_white', 'std_err_material_count_white', 'average_material_count_black', 'std_dev_material_count_black', 'std_err_material_count_black', 'black_model_prompt_tokens', 'average_black_model_prompt_tokens', 'std_dev_black_model_prompt_tokens', 'std_err_black_model_prompt_tokens', 'black_model_completion_tokens', 'average_black_model_completion_tokens', 'std_dev_black_model_completion_tokens', 'std_err_black_model_completion_tokens', 'black_model_total_tokens', 'average_black_model_total_tokens', 'std_dev_black_model_total_tokens', 'std_err_black_model_total_tokens']\n"
     ]
    }
   ],
   "source": [
    "# Compare aggregates from aggr.csv to thoses ones obtained from plain.csv, check number of games/logs to to match (the number of log files == sum of total games)\n",
    "\n",
    "# df_plain columns\n",
    "# path,time_started,winner,reason,number_of_moves,player_white_name,player_white_wrong_moves,player_white_wrong_actions,player_white_reflections_used,player_white_reflections_used_before_board,player_white_model,material_count_white,material_count_black,player_black_name,player_black_wrong_moves,player_black_wrong_actions,player_black_reflections_used,player_black_reflections_used_before_board,player_black_model,black_model_prompt_tokens,black_model_completion_tokens,black_model_total_tokens\n",
    "\n",
    "\n",
    "# Group the data by 'player_black_model' and calculate the number of moves for each model\n",
    "grouped_data = df_plain.groupby('model')['number_of_moves']\n",
    "\n",
    "aggregates_from_plain = df_plain.groupby('model').agg(\n",
    "    total_games=('number_of_moves', 'count'),\n",
    "    black_llm_wins=('winner', lambda x: (x == 'Player_Black').sum()),\n",
    "    white_rand_wins=('winner', lambda x: (x == 'Random_Player').sum()),\n",
    "    draws=('winner', lambda x: (x == 'NONE').sum()),\n",
    "    sum_wrong_actions=('player_black_wrong_actions', 'sum'),\n",
    "    sum_wrong_moves=('player_black_wrong_moves', 'sum'),\n",
    "    sum_moves=('number_of_moves', 'sum'),\n",
    "    min_moves=('number_of_moves', 'min'),\n",
    "    max_moves=('number_of_moves', 'max'),\n",
    "    average_moves=('number_of_moves', 'mean'),\n",
    "    std_dev_moves=('number_of_moves', lambda x: x.std(ddof=1)),  # Sample standard deviation\n",
    "    average_material_count_white=('material_count_white', 'mean'),\n",
    "    std_dev_material_count_white=('material_count_white', lambda x: x.std(ddof=1)),\n",
    "    std_err_material_count_white=('material_count_white', lambda x: x.std(ddof=1) / (len(x) ** 0.5)),\n",
    "    average_material_count_black=('material_count_black', 'mean'),\n",
    "    std_dev_material_count_black=('material_count_black', lambda x: x.std(ddof=1)),\n",
    "    std_err_material_count_black=('material_count_black', lambda x: x.std(ddof=1) / (len(x) ** 0.5)),\n",
    "    black_model_prompt_tokens=('black_model_prompt_tokens', 'sum'),\n",
    "    average_black_model_prompt_tokens=('black_model_prompt_tokens', 'mean'),\n",
    "    std_dev_black_model_prompt_tokens=('black_model_prompt_tokens', lambda x: x.std(ddof=1)),\n",
    "    std_err_black_model_prompt_tokens=('black_model_prompt_tokens', lambda x: x.std(ddof=1) / (len(x) ** 0.5)),\n",
    "    black_model_completion_tokens=('black_model_completion_tokens', 'sum'),\n",
    "    average_black_model_completion_tokens=('black_model_completion_tokens', 'mean'),\n",
    "    std_dev_black_model_completion_tokens=('black_model_completion_tokens', lambda x: x.std(ddof=1)),\n",
    "    std_err_black_model_completion_tokens=('black_model_completion_tokens', lambda x: x.std(ddof=1) / (len(x) ** 0.5)),\n",
    "    black_model_total_tokens=('black_model_total_tokens', 'sum'),\n",
    "    average_black_model_total_tokens=('black_model_total_tokens', 'mean'),\n",
    "    std_dev_black_model_total_tokens=('black_model_total_tokens', lambda x: x.std(ddof=1)),\n",
    "    std_err_black_model_total_tokens=('black_model_total_tokens', lambda x: x.std(ddof=1) / (len(x) ** 0.5))\n",
    ").reset_index() \n",
    "\n",
    "# # Now compute normalized values\n",
    "# aggregates['wrong_actions_per_100moves'] = (aggregates['sum_wrong_actions'] / aggregates['sum_moves']) * 100\n",
    "# aggregates['wrong_moves_per_100moves'] = (aggregates['sum_wrong_moves'] / aggregates['sum_moves']) * 100\n",
    "\n",
    "# Calculate and print the sum of total_games in df_aggr\n",
    "df_aggr_total_games_sum = df_aggr[\"total_games\"].sum()\n",
    "print(f\"Sum of total_games in df_aggr: {df_aggr_total_games_sum}\")\n",
    "\n",
    "# Calculate and print the sum of total_games in aggregates\n",
    "aggregates_total_games_sum = aggregates_from_plain[\"total_games\"].sum()\n",
    "print(f\"Sum of total_games in aggregates: {aggregates_total_games_sum}\")\n",
    "\n",
    "# Print column names from df_aggr\n",
    "print(\"Columns in df_aggr:\")\n",
    "print(df_aggr.columns.tolist())\n",
    "\n",
    "# Print column names from aggregates\n",
    "print(\"Columns in aggregates_from_plain:\")\n",
    "print(aggregates_from_plain.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                model  total_games  black_llm_wins  white_rand_wins  draws  sum_wrong_actions  sum_wrong_moves  sum_moves  min_moves  max_moves  average_moves  std_dev_moves  average_material_count_white  std_dev_material_count_white  std_err_material_count_white  average_material_count_black  std_dev_material_count_black  std_err_material_count_black  black_model_prompt_tokens  average_black_model_prompt_tokens  std_dev_black_model_prompt_tokens  std_err_black_model_prompt_tokens  black_model_completion_tokens  average_black_model_completion_tokens  std_dev_black_model_completion_tokens  std_err_black_model_completion_tokens  black_model_total_tokens  average_black_model_total_tokens  std_dev_black_model_total_tokens  std_err_black_model_total_tokens\n",
      "0                        anthropic.claude-v3-5-sonnet           30               0                8     22                  0               12       5148         10        200     171.600000      55.148452                     22.500000                     11.840171                      2.161710                     15.800000                      9.918287                      1.810823                    2997738                       99924.600000                       31430.810177                        5738.454578                         417373                           13912.433333                            4499.171255                             821.432529                   3415111                     113837.033333                      35876.553478                       6550.132542\n",
      "1                     anthropic.claude-v3-5-sonnet-v1           60               4                8     48                  0                3      11003         30        200     183.383333      40.117662                     17.366667                      9.425833                      1.216870                     13.200000                      8.297028                      1.071142                    6420741                      107012.350000                       23174.208955                        2991.777512                         884906                           14748.433333                            3464.280831                             447.236732                   7305647                     121760.783333                      26559.219852                       3428.780539\n",
      "2                     anthropic.claude-v3-5-sonnet-v2           60               2                5     53                  0                8      11292         22        200     188.200000      37.124984                     13.833333                      8.843587                      1.141702                     10.816667                      7.740476                      0.999291                    6510330                      108505.500000                       21106.968141                        2724.897870                        1025929                           17098.816667                            3546.391322                             457.837151                   7536259                     125604.316667                      24557.611939                       3170.374069\n",
      "3                           anthropic.claude-v3-haiku           40               0               40      0                  7                4       1334          2         98      33.350000      25.662054                     37.150000                      3.731708                      0.590035                     36.725000                      3.389180                      0.535876                    2052970                       51324.250000                       25599.363036                        4047.614692                         280994                            7024.850000                            3915.958360                             619.167382                   2333964                      58349.100000                      29430.260033                       4653.332692\n",
      "4                            anthropic.claude-v3-opus           30               0                5     25                  1                7       4968         18        200     165.600000      66.459010                     21.633333                     10.189526                      1.860344                     15.633333                     10.479811                      1.913343                    2833235                       94441.166667                       37643.162611                        6872.669766                         361980                           12066.000000                            5400.639617                             986.017381                   3195215                     106507.166667                      42754.653766                       7805.896102\n",
      "5                                       deepseek-chat           70               0               68      2                 10              180       4043          8        200      57.757143      50.628638                     30.528571                      8.534196                      1.020032                     32.171429                      9.020060                      1.078103                    2614032                       37343.314286                       32947.765500                        3938.011194                         998322                           14261.742857                           13253.058870                            1584.043512                   3612354                      51605.057143                      46069.513255                       5506.360026\n",
      "6                   deepseek-r1-distill-qwen-14b@q8_0           30               0               30      0                 82                8         78          2          6       2.600000       1.069966                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                     175575                        5852.500000                        2308.853391                         421.537028                         239699                            7989.966667                            2862.235375                             522.570293                    415274                      13842.466667                       4575.447223                        835.358552\n",
      "7     deepseek-r1-distill-qwen-32b@q4_k_m|isol_temp06           30               0               30      0                 73                7        110          2         10       3.666667       2.353769                     38.966667                      0.182574                      0.033333                     39.000000                      0.000000                      0.000000                     218374                        7279.133333                        5590.071690                        1020.602788                         239121                            7970.700000                            4389.020503                             801.321845                    457495                      15249.833333                       8961.830782                       1636.198959\n",
      "8   deepseek-r1-distill-qwen-32b@q4_k_m|noisol_temp03           44               0               43      1                 92               24        153          1          8       3.477273       1.649364                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                     310199                        7049.977273                        5119.269263                         771.758879                         328701                            7470.477273                            3193.951511                             481.506307                    638900                      14520.454545                       7459.584471                       1124.574672\n",
      "9   deepseek-r1-distill-qwen-32b@q4_k_m|noisol_temp06           34               0               34      0                 81               18        114          2          8       3.352941       1.756069                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                     191512                        5632.705882                        3587.376762                         615.230039                         252227                            7418.441176                            4112.025566                             705.206567                    443739                      13051.147059                       7022.145654                       1204.288044\n",
      "10                                  deepseek-reasoner           31               7               18      6                  9               44       2845          4        200      91.774194      65.017285                     10.806452                     14.005759                      2.515509                     21.935484                     13.971245                      2.509310                     901267                       29073.129032                       18955.745039                        3404.552313                       13044247                          420782.161290                          284489.545676                           51095.830775                  13945514                     449855.290323                     302900.328633                      54402.505008\n",
      "11                               gemini-1.5-flash-001           30               0               20     10                 18               36       2524          4        200      84.133333      93.697508                     35.666667                      6.047703                      1.104154                     29.266667                     12.119899                      2.212781                    1234960                       41165.333333                       43229.220495                        7892.539736                          50265                            1675.500000                            1751.266630                             319.736079                   1285225                      42840.833333                      44978.370502                       8211.889375\n",
      "12                        gemini-1.5-pro-preview-0409           40               0               37      3                 14               71       2626          5        200      65.650000      59.733833                     33.075000                      7.169692                      1.133628                     29.750000                      9.662908                      1.527840                    1665689                       41642.225000                       36090.581451                        5706.421973                          35145                             878.625000                             776.182727                             122.725265                   1700834                      42520.850000                      36861.854792                       5828.370996\n",
      "13                               gemini-2.0-flash-exp           30               0               28      2                  0               81       2576          6        200      85.866667      73.623335                     27.166667                     12.512293                      2.284422                     26.933333                     12.250076                      2.236548                    1720039                       57334.633333                       46937.656873                        8569.604489                         433155                           14438.500000                           13984.011675                            2553.119546                   2153194                      71773.133333                      60551.347963                      11055.113056\n",
      "14                gemini-2.0-flash-thinking-exp-01-21           33               0               31      1                  7                1       1341          2        119      40.636364      25.123219                     33.727273                      6.969903                      1.213304                     33.212121                      6.989982                      1.216800                     625305                       18948.636364                       11984.287278                        2086.196638                          23829                             722.090909                             452.317461                              78.738363                    649134                      19670.727273                      12417.200151                       2161.557096\n",
      "15                 gemini-2.0-flash-thinking-exp-1219           30               0               30      0                 89                1         70          2          6       2.333333       0.922266                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                     224271                        7475.700000                        5171.426010                         944.168893                          50718                            1690.600000                            1223.048328                             223.297053                    274989                       9166.300000                       6359.886169                       1161.151039\n",
      "16                              gemma-2-27b-it@q6_k_l           30               0               22      8                  8               52       3268         10        200     108.933333      70.564196                     26.333333                     10.306788                      1.881753                     25.466667                     11.717165                      2.139252                    2028385                       67612.833333                       40372.849765                        7371.040176                         179885                            5996.166667                            3666.107614                             669.336613                   2208270                      73609.000000                      44020.499913                       8037.006932\n",
      "17                                 gemma-2-9b-it-8bit           30               0               26      4                 45               31       2075          2        200      69.166667      72.833340                     34.133333                      7.758125                      1.416433                     32.000000                      9.180189                      1.676065                    1201066                       40035.533333                       37414.976944                        6831.008954                         120608                            4020.266667                            4098.483058                             748.277207                   1321674                      44055.800000                      41506.958140                       7578.099089\n",
      "18                                       gemma2-9b-it           35               0               35      0                 83               22        516          2         88      14.742857      15.897360                     38.314286                      2.272229                      0.384077                     38.714286                      1.045197                      0.176671                     342837                        9795.342857                        8629.850517                        1458.710976                          10432                             298.057143                             270.525735                              45.727195                    353269                      10093.400000                       8898.773548                       1504.167265\n",
      "19                                  gpt-35-turbo-0125           30               0               30      0                 90                0         86          2         10       2.866667       1.870521                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                      89137                        2971.233333                        1737.390328                         317.202625                           7054                             235.133333                             162.405566                              29.651064                     96191                       3206.366667                       1868.210309                        341.086976\n",
      "20                                  gpt-35-turbo-0301           30               0               30      0                 90                0         68          2          4       2.266667       0.691492                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                      57543                        1918.100000                         470.751736                          85.947115                           4560                             152.000000                              86.451900                              15.783885                     62103                       2070.100000                        523.625251                         95.600454\n",
      "21                                  gpt-35-turbo-0613           30               0               30      0                 90                0        124          2         12       4.133333       2.825174                     38.966667                      0.182574                      0.033333                     39.000000                      0.000000                      0.000000                     129031                        4301.033333                        3118.625178                         569.380453                          11610                             387.000000                             453.451971                              82.788624                    140641                       4688.033333                       3549.442924                        648.036652\n",
      "22                                  gpt-35-turbo-1106           30               0               30      0                 88                2        108          2         10       3.600000       2.429701                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                      49156                        1638.533333                        1022.582725                         186.697209                           5219                             173.966667                             146.285381                              26.707934                     54375                       1812.500000                       1159.306890                        211.659512\n",
      "23                                         gpt-4-0613           17               0                2     15                  0                0       3232         35        200     190.117647      39.979498                     20.411765                      7.211612                      1.749073                     14.764706                      9.437488                      2.288927                     548490                       32264.117647                        6971.884680                        1690.930408                          21268                            1251.058824                             267.963260                              64.990637                    569758                      33515.176471                       7233.832536                       1754.462095\n",
      "24                                     gpt-4-32k-0613           11               0                1     10                  0                0       2157        157        200     196.090909      12.964988                     17.818182                      6.193839                      1.867513                     12.909091                      7.272614                      2.192776                     369433                       33584.818182                        3315.034082                         999.520383                          14164                            1287.636364                              93.157150                              28.087937                    383597                      34872.454545                       3398.809390                       1024.779589\n",
      "25                             gpt-4-turbo-2024-04-09           30               0                2     28                  0                0       5786         45        200     192.866667      29.930648                     20.800000                      9.654015                      1.762574                     15.433333                      8.033050                      1.466627                    2439800                       81326.666667                       12990.823457                        2371.789016                          34906                            1163.533333                             183.324422                              33.470307                   2474706                      82490.200000                      13172.500976                       2404.958641\n",
      "26                                  gpt-4o-2024-05-13           60               0               12     48                  1               16      11057         32        200     184.283333      37.280927                     17.350000                      7.049041                      0.910027                     13.633333                      7.955313                      1.027026                    5019535                       83658.916667                       16245.381329                        2097.269711                         346468                            5774.466667                            1250.698469                             161.464478                   5366003                      89433.383333                      17379.858173                       2243.730042\n",
      "27                                  gpt-4o-2024-08-06           60               1                9     50                  0                1      11214         51        200     186.900000      31.814451                     19.333333                      8.711315                      1.124626                     14.483333                      7.349603                      0.948830                    4649382                       77489.700000                       13178.128918                        1701.289128                          86384                            1439.733333                             322.071624                              41.579268                   4735766                      78929.433333                      13375.152328                       1726.724741\n",
      "28                                  gpt-4o-2024-11-20           71               3                6     62                  1                1      13470         29        200     189.718310      32.637482                     19.901408                      8.637385                      1.025069                     11.901408                      8.055442                      0.956005                    6229300                       87736.619718                       15270.252253                        1812.245529                         681249                            9595.056338                            1664.244521                             197.509487                   6910549                      97331.676056                      16913.218250                       2007.229720\n",
      "29                             gpt-4o-mini-2024-07-18           30               0               12     18                 13               24       4481         10        200     149.366667      70.243165                     24.866667                      9.179187                      1.675883                     20.433333                      9.339140                      1.705086                    2438163                       81272.100000                       38498.972214                        7028.918507                         484917                           16163.900000                            7665.824630                            1399.581691                   2923080                      97436.000000                      45977.157330                       8394.242067\n",
      "30                            granite-3.1-8b-instruct           30               0               30      0                 47               12        126          2         10       4.200000       2.483046                     39.000000                      0.000000                      0.000000                     38.966667                      0.182574                      0.033333                     377120                       12570.666667                        6776.780969                        1237.265268                          59110                            1970.333333                            1959.383970                             357.732933                    436230                      14541.000000                       8067.046971                       1472.834533\n",
      "31                                        grok-2-1212           49               2               32     15                  1               93       5593         26        200     114.142857      67.887161                     22.387755                      9.677759                      1.382537                     25.326531                     11.336497                      1.619500                    2811967                       57387.081633                       34089.885778                        4869.983683                         370417                            7559.530612                            4534.332288                             647.761755                   3182384                      64946.612245                      38618.284059                       5516.897723\n",
      "32                              internlm3-8b-instruct           30               0               30      0                 15               39        108          2          8       3.600000       1.922642                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                     690605                       23020.166667                       15637.186629                        2854.946617                         166741                            5558.033333                            3385.668797                             618.135724                    857346                      28578.200000                      18227.568151                       3327.883415\n",
      "33                                    llama-2-7b-chat           30               0               30      0                 88                2         64          2          4       2.133333       0.507416                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                      75064                        2502.133333                         715.394838                         130.612630                           7444                             248.133333                             537.681789                              98.166815                     82508                       2750.266667                       1121.108347                        204.685444\n",
      "34                           llama-3-70b-instruct-awq           30               0               15     15                  2               41       4449         14        200     148.300000      62.428525                     26.966667                      7.716902                      1.408907                     21.566667                     10.129109                      1.849314                    2349787                       78326.233333                       30982.931686                        5656.683527                         185118                            6170.600000                            2390.742773                             436.487915                   2534905                      84496.833333                      33363.432949                       6091.301607\n",
      "35                               llama-3.1-8b-instant           60               0               60      0                 27              146       1754          6         98      29.233333      21.588106                     37.533333                      2.977126                      0.384345                     36.616667                      4.329997                      0.559000                    1635437                       27257.283333                       18798.187530                        2426.835575                         292050                            4867.500000                            4008.826137                             517.537229                   1927487                      32124.783333                      21552.548349                       2782.422027\n",
      "36                       llama-3.2-90b-vision-preview            7               0                5      2                  1               14        730          6        200     104.285714      82.900974                     32.428571                      9.795529                      3.702362                     24.142857                     13.643418                      5.156727                     399909                       57129.857143                       42729.017367                       16150.050531                          24475                            3496.428571                            2560.662340                             967.839392                    424384                      60626.285714                      45287.357333                      17117.012148\n",
      "37                                      llama-3.3-70b           42               0               38      4                  2              100       2886          4        200      68.714286      69.413320                     33.452381                      8.121643                      1.253197                     30.904762                     11.604897                      1.790674                    2032359                       48389.500000                       45068.443827                        6954.211860                         297205                            7076.309524                            6591.585399                            1017.103709                   2329564                      55465.809524                      51644.858747                       7968.974713\n",
      "38                            llama-3.3-70b-versatile            2               0                2      0                  0                6         60         20         40      30.000000      14.142136                     39.000000                      0.000000                      0.000000                     37.000000                      2.828427                      2.000000                      43372                       21686.000000                        7761.204030                        5488.000000                           7018                            3509.000000                             330.925974                             234.000000                     50390                      25195.000000                       8092.130004                       5722.000000\n",
      "39                                     llama3-8b-8192           60               0               60      0                104               66        902          4         50      15.033333      10.541229                     38.683333                      1.065510                      0.137557                     38.200000                      2.097618                      0.270801                     749595                       12493.250000                        8608.500881                        1111.352685                          51432                             857.200000                             918.271530                             118.548345                    801027                      13350.450000                       9462.124489                       1221.555019\n",
      "40                                        llama3.1-8b           90               0               87      3                 44              188       2436          4        100      27.066667      22.241170                     37.833333                      2.545099                      0.268277                     37.200000                      3.736248                      0.393835                    1995033                       22167.033333                       17305.284142                        1824.137115                         394879                            4387.544444                            3444.042452                             363.033950                   2389912                      26554.577778                      18845.049666                       1986.442652\n",
      "41                    meta-llama-3.1-8b-instruct-fp16           30               0               30      0                 19               61        830          4         84      27.666667      22.713103                     37.000000                      3.393706                      0.619603                     36.733333                      4.093168                      0.747307                     577065                       19235.500000                       13814.839737                        2522.233117                          59644                            1988.133333                            1535.253652                             280.297685                    636709                      21223.633333                      15332.706924                       2799.356483\n",
      "42                         ministral-8b-instruct-2410           30               0               30      0                 56               34        282          2         26       9.400000       6.911260                     38.600000                      1.714039                      0.312939                     38.766667                      0.773854                      0.141286                     179727                        5990.900000                        4187.903066                         764.602993                          20336                             677.866667                             447.989127                              81.791250                    200063                       6668.766667                       4622.885311                        844.019522\n",
      "43                     mistral-nemo-12b-instruct-2407           30               0               30      0                 79               11        202          2         20       6.733333       5.132273                     38.666667                      1.647011                      0.300702                     38.766667                      0.678911                      0.123952                     127958                        4265.266667                        2798.816325                         510.991612                           9635                             321.166667                             338.218057                              61.749886                    137593                       4586.433333                       3081.201419                        562.547840\n",
      "44                        mistral-small-instruct-2409           30               0               30      0                 58               32        272          2         22       9.066667       5.323554                     38.833333                      0.592093                      0.108101                     38.866667                      0.345746                      0.063124                     216674                        7222.466667                        4720.607959                         861.861155                          24002                             800.066667                             518.604290                              94.683756                    240676                       8022.533333                       5206.932254                        950.651417\n",
      "45                                 mixtral-8x7b-32768           20               0               20      0                 60                0         40          2          2       2.000000       0.000000                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                      10320                         516.000000                           0.000000                           0.000000                            660                              33.000000                               0.000000                               0.000000                     10980                        549.000000                          0.000000                          0.000000\n",
      "46                                 o1-mini-2024-09-12           30               9                6     15                  2                8       4282         28        200     142.733333      61.450812                      7.033333                     11.330409                      2.068640                     17.666667                     12.208910                      2.229032                    1020768                       34025.600000                       21743.815910                        3969.859487                        5228905                          174296.833333                           81750.813772                           14925.588266                   6249673                     208322.433333                     102023.236968                      18626.809426\n",
      "47                              o1-preview-2024-09-12           30              14                3     13                  4               10       3744         20        200     124.800000      61.522858                      4.033333                      8.066462                      1.472728                     17.800000                     14.641462                      2.673153                    1184284                       39476.133333                       19071.814536                        3482.021011                        9959309                          331976.966667                          154583.041960                           28222.873030                  11143593                     371453.100000                     173528.379843                      31681.802669\n",
      "48                                              phi-4           30               0               30      0                 44               46        232          4         22       7.733333       4.630732                     39.000000                      0.000000                      0.000000                     39.000000                      0.000000                      0.000000                     236743                        7891.433333                        3682.096982                         672.255859                          77382                            2579.400000                            1378.192484                             251.622371                    314125                      10470.833333                       4965.091402                        906.497520\n",
      "49                                qwen-max-2025-01-25           13               0                0     13                  0                0       2600        200        200     200.000000       0.000000                     21.000000                      8.698659                      2.412574                     16.230769                      5.418392                      1.502792                    1041952                       80150.153846                        1463.634338                         405.939127                          15905                            1223.461538                              44.033350                              12.212654                   1057857                      81373.615385                       1456.816823                        404.048289\n",
      "50              qwen2.5-14b-instruct-1m@q4_k_m@q4_k_m            3               0                1      2                  0                3        500        100        200     166.666667      57.735027                     27.000000                      8.000000                      4.618802                     16.333333                     10.066446                      5.811865                     308071                      102690.333333                       34635.660097                       19996.907680                         107395                           35798.333333                           11373.297250                            6566.376229                    415466                     138488.666667                      45979.761943                      26546.427935\n",
      "51                          qwen2.5-14b-instruct@q8_0           30               0               30      0                 29               59        398          2         42      13.266667      10.027319                     38.400000                      1.904622                      0.347735                     38.566667                      1.040004                      0.189878                     303196                       10106.533333                        6600.145927                        1205.016269                          59951                            1998.366667                            1512.944434                             276.224598                    363147                      12104.900000                       8078.709385                       1474.963789\n",
      "52                               qwen2.5-72b-instruct           10               0               10      0                  4               26        446          6        100      44.600000      33.559897                     34.400000                      5.719363                      1.808621                     34.600000                      6.345602                      2.006656                     304144                       30414.400000                       21578.006798                        6823.564885                         103378                           10337.800000                            8122.848184                            2568.670135                    407522                      40752.200000                      29508.060747                       9331.268130\n",
      "53                            qwen2.5-vl-72b-instruct           10               0               10      0                  1               26        244          8         54      24.400000      15.966632                     38.300000                      1.567021                      0.495536                     35.900000                      5.258855                      1.662996                     208793                       20879.300000                       10020.335535                        3168.708321                          88102                            8810.200000                            4735.327158                            1497.441928                    296895                      29689.500000                      14491.361413                       4582.570846\n",
      "54                             qwq-32b-preview@q4_k_m           30               0               30      0                 44               17        239          2         22       7.966667       4.845783                     38.966667                      0.182574                      0.033333                     38.866667                      0.571346                      0.104313                    1406225                       46874.166667                       25399.668278                        4637.323756                         695012                           23167.066667                           14852.897541                            2711.755676                   2101237                      70041.233333                      38001.717792                       6938.132686\n",
      "55                                 sky-t1-32b-preview           30               0               30      0                  9               59        415          2         46      13.833333       9.299920                     38.800000                      0.761124                      0.138962                     38.766667                      0.773854                      0.141286                     932760                       31092.000000                       25521.986111                        4659.655835                         504706                           16823.533333                           16537.079423                            3019.243812                   1437466                      47915.533333                      40366.426594                       7369.867470\n"
     ]
    }
   ],
   "source": [
    "# Print the calculated aggregates\n",
    "print(aggregates_from_plain.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'deepseek-r1-distill-qwen-32b@q4_k_m' not found in aggregates_from_plain.\n",
      "Discrepancy for model 'gemini-2.0-flash-thinking-exp-01-21' in column 'draws':\n",
      "  df_aggr value: 2\n",
      "  aggregates_from_plain value: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map the best matches between df_aggr and aggregates_from_plain column names\n",
    "column_mapping = {\n",
    "    'model_name': 'model',\n",
    "    'total_games': 'total_games',\n",
    "    'black_llm_wins': 'black_llm_wins',\n",
    "    'white_rand_wins': 'white_rand_wins',\n",
    "    'draws': 'draws',\n",
    "    'black_llm_wins_percent': None,  # No direct match in aggregates_from_plain\n",
    "    'black_llm_draws_percent': None,  # No direct match in aggregates_from_plain\n",
    "    'llm_total_moves': 'sum_moves',\n",
    "    'llm_wrong_actions': 'sum_wrong_actions',\n",
    "    'llm_wrong_moves': 'sum_wrong_moves',\n",
    "    'llm_avg_material': 'average_material_count_black',\n",
    "    'llm_std_dev_material': 'std_dev_material_count_black',\n",
    "    'rand_avg_material': 'average_material_count_white',\n",
    "    'rand_std_dev_material': 'std_dev_material_count_white',\n",
    "    'material_diff_llm_minus_rand': None,  # No direct match in aggregates_from_plain\n",
    "    'material_diff_llm_minus_rand_per_100moves': None,  # No direct match in aggregates_from_plain\n",
    "    'wrong_actions_per_100moves': None,  # No direct match in aggregates_from_plain\n",
    "    'wrong_moves_per_100moves': None,  # No direct match in aggregates_from_plain\n",
    "    'wrong_actions_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'wrong_moves_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'mistakes_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'std_dev_wrong_actions_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'std_dev_wrong_moves_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'std_dev_mistakes_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'average_moves': 'average_moves',\n",
    "    'std_dev_moves': 'std_dev_moves',\n",
    "    'completion_tokens_black': 'black_model_completion_tokens',\n",
    "    'completion_tokens_black_per_move': None,  # No direct match in aggregates_from_plain\n",
    "    'min_moves': 'min_moves',\n",
    "    'max_moves': 'max_moves',\n",
    "    'prompt_tokens_black': 'black_model_prompt_tokens',\n",
    "    'total_tokens_black': 'black_model_total_tokens',\n",
    "    'moe_material_diff': None,  # No direct match in aggregates_from_plain\n",
    "    'moe_avg_moves': None,  # No direct match in aggregates_from_plain\n",
    "    'moe_wrong_actions_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'moe_wrong_moves_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "    'moe_mistakes_per_1000moves': None,  # No direct match in aggregates_from_plain\n",
    "}\n",
    "\n",
    "# Iterate over the rows in df_aggr\n",
    "for index, row in df_aggr.iterrows():\n",
    "    model_name = row['model_name']\n",
    "    \n",
    "    # Find the corresponding row in aggregates_from_plain\n",
    "    matching_row = aggregates_from_plain[aggregates_from_plain['model'] == model_name]\n",
    "    \n",
    "    if matching_row.empty:\n",
    "        print(f\"Model '{model_name}' not found in aggregates_from_plain.\")\n",
    "        continue\n",
    "    \n",
    "    # Compare the values of mapped columns\n",
    "    for df_aggr_col, aggregates_col in column_mapping.items():\n",
    "        if aggregates_col is None:\n",
    "            # Skip columns that have no mapping\n",
    "            continue\n",
    "        \n",
    "        df_aggr_value = row[df_aggr_col]\n",
    "        \n",
    "        try:\n",
    "            # Safely access the value in matching_row\n",
    "            aggregates_value = matching_row.iloc[0].get(aggregates_col, None)\n",
    "        except KeyError:\n",
    "            print(f\"Column '{aggregates_col}' not found in aggregates_from_plain for model '{model_name}'.\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure both values are converted to numeric if possible\n",
    "        try:\n",
    "            df_aggr_value = pd.to_numeric(df_aggr_value, errors='coerce')\n",
    "            aggregates_value = pd.to_numeric(aggregates_value, errors='coerce')\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting values to numeric for column '{df_aggr_col}': {e}\")\n",
    "            continue\n",
    "        \n",
    "        if not pd.isna(df_aggr_value) and not pd.isna(aggregates_value):\n",
    "            if not np.isclose(df_aggr_value, aggregates_value, atol=1e-6):\n",
    "                print(f\"Discrepancy for model '{model_name}' in column '{df_aggr_col}':\")\n",
    "                print(f\"  df_aggr value: {df_aggr_value}\")\n",
    "                print(f\"  aggregates_from_plain value: {aggregates_value}\")\n",
    "        elif pd.isna(df_aggr_value) != pd.isna(aggregates_value):\n",
    "            print(f\"Discrepancy for model '{model_name}' in column '{df_aggr_col}':\")\n",
    "            print(f\"  df_aggr value: {df_aggr_value}\")\n",
    "            print(f\"  aggregates_from_plain value: {aggregates_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
